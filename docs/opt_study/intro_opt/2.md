---
layout: page-sidenav
group: "Introduction to Optimization"
title: "2. Convex Sets"
---

Affine and Convex Sets
----------------------

**Affine**

- **Deinition:** A set $$S \subseteq \mathbf{R^n}$$ is affine if the line through any two distinct points in $$S$$ lies in $$S$$. That is, $$S$$ is an affine set if for any $$x_1,x_2 \in S$$, and $$\theta \in \mathbf{R}$$, we have

$$z:=\theta x_1+(1-\theta)x_2 \in S$$

**Convex**

- **Deinition:** A set $$S \subseteq \mathbf{R^n}$$ is convex if the line segment between any two points in $$S$$ lies in $$S$$. That is, for any $$x_1,x_2 \in S$$, and $$\theta \in [0,1]$$, we have

$$z:=\theta x_1+(1-\theta)x_2 \in S$$

- 명확히, affine set은 convex set지만 역은 참이 아니다.

**Affine combination**

- **Definition:** A point $$x$$ is called an affine combination of points $$x_1,...,x_k$$ if there exists $$\theta_1,...,\theta_k$$ such that

$$\theta_1x_1+\ldots+\theta_kx_k, \sum_{l=1}^{k}\theta_l = 1$$

**Covex combination**

- **Definition:** A point $$x$$ is called an convex combination of points $$x_1,...,x_k$$ if there exists $$\theta_1,...,\theta_k$$ such that

$$\theta_1x_1+\ldots+\theta_kx_k, \sum_{l=1}^{k}\theta_l = 1, \theta_k \ge 0, \forall k$$

- $$x$$를 random variable로 생각하면, convex combination은 $$P(x=x_l)=\theta_l$$일때 $$E[x]$$로 생각될 수 있다.
- **Fact:** An convex(affine) set $$S$$ contains every convex(affine) combination of its points.
	- **Proof**(by induction)

clearly $$x_1,x_2 \in S$$ and we have

$$\theta x_1+(1-\theta)x_2 \in S, x_1,x_2 \in S, \theta \in [0,1]$$

Assume that

$$\theta_1x_1+\ldots+\theta_kx_k, x_1,...,x_k \in S, \sum_{l=1}^{k}\theta_l = 1, \theta_l \ge 0, \forall l$$

Consider the convex combination $$x_1,...,x_{k+1} \in S$$

$$z:=\alpha_1x_1+\ldots+\alpha_kx_k+\alpha_{k+1}x_{k+1}, \sum_{l=1}^{k+1}\alpha_l = 1, \alpha_l \ge 0, \forall l$$

if $$\alpha_{k+1}=1$$, then we are done. if not, let $$s:=\sum_{l=1}^{k}\alpha_l=1-a_{k+1}$$

Then

$$z=\alpha_{k+1}x_{k+1}+(1-\alpha_{k+1})(\frac{\alpha_1}{s}x_1+\ldots+\frac{\alpha_k}{s}x_k)$$

Note that by definition

$$\frac{\alpha_l}{s} \ge 0, \forall l \; \& \sum_{l=1}^{k}\frac{\alpha_l}{s}=1$$

Hence, by the induction argument
$$\frac{\alpha_1}{s}x_1+\ldots+\frac{\alpha_k}{s}x_k \in S$$

We have the desired result based on the definition of convex(affine) set

**Affine hull**

- **Definition:** The set of all affine combination of points in some set $$S \subseteq \mathbf{R^n}$$ is called affine hull of $$S$$, and is denoted by

$$\text{aff}(S)=\{\theta_1x_1+\ldots+\theta_kx_k\vert x_1,\ldots x_k \in S, \sum_{l=1}^{k}\theta_l = 1\}$$

Note that $$\text{aff}(S)$$ is the smallest affine set that contains $$S$$. That is if $$C$$ is an affine set that contains $$S$$, then $$\text{aff}(S) \subseteq C$$

**Convex hull**

- **Definition:** The set of all convex combination of points in some set $$S \subseteq \mathbf{R^n}$$ is called convex hull of $$S$$, and is denoted by

$$\text{conv}(S)=\{\theta_1x_1+\ldots+\theta_kx_k\vert x_1,\ldots x_k \in S, \sum_{l=1}^{k}\theta_l = 1,\theta_k \ge 0 ,\forall k\}$$

$$\text{conv}(S)$$ is the smallest convex set that contain $$S$$

Cones
-----

**Cone**

- **Definition:** A set $$C$$ is a cone if for every $$x \in C$$ and $$\theta \ge 0, \theta x \in C$$. A set C is a convex cone if $$C$$ is convex and cone. That is, for any $$x_1,x_2 \in C$$ and $$\theta_1,\theta_2 \ge 0$$, we have

$$\theta_1x_1 + \theta_2x_2 \in C$$

Lemma: Assume that $$C$$ is convex. Then the set

$$\text{cone}(C) = \{\gamma x; x\in C, \gamma \ge 0\}$$

is a convex cone

Hyperplane and Halfspaces
------------------------

**Hyperplane**

- **Definition:**

$$\{x\vert a^Tx=b\}$$

- where $$a \in \mathbf{R^n}$$ and $$b \in \mathbf{R}$$. If $$b=0$$, then the hyperplane passes the origin. 참고로, $$a$$는 normal vector of $$x$$.
- 다르게 표현하면

$$\{x\vert a^T(x-x_0)=0\}$$

**Halfspace**

- **Definition:**

$$\{x\vert a^Tx\le b\}$$

- 다르게 표현하면

$$\{x\vert a^T(x-x_0)\le 0\}$$

Euclidean Balls and Ellipsoid
-----------------------------

**Euclidean ball**

- **Definition:**

$$B_\delta(x_0)=\{x\vert \; \vert\vert x-x_0\vert\vert \le \delta\}=\{x\vert \; (x-x_0)^T(x-x_0) \le \delta\}=\{x_0+\delta u\vert \; \vert\vert u\vert\vert \le 1\}$$

- is a convex set.

**Ellipsoid**

- **Definition:**

$$\varepsilon=\{x\vert \; \vert\vert x-x_0\vert\vert_{p^{-1}} \le 1\}=\{x\vert \; (x-x_0)^TP^{-1}(x-x_0) \le 1\}$$

- where P > 0, is a convex set.
- The ellipsoid can also be written as

$$\varepsilon=\{x_0 + Au\vert \; \vert\vert u\vert\vert \le 1\}$$

- 이전 표현식과 같음을 보여보자.
- 참고로, $$P>0$$으로 $$P=AA$$를 만족하는 A가 존재한다.
- $$y = x-x_0$$으로 두면,

$$(x-x_0)^TP^{-1}(x-x_0) = y^T(A^{-1})^TA^{-1}y=(A^{-1}y)^T\cdot(A^{-1}y)=\vert\vert A^{-1}y\vert\vert \le 1$$

- $$u=A^{-1}y$$로 두면, 두 표현식이 같음을 보일 수 있다.
- 특별히, $$P=I$$일때, norm ball이라 부른다.

Polyhedron
----------

**Polyhedron**

- **Definition:**

$$\mathbf{P}=\{x\vert Ax \le b, Cx=d\}$$

- convex set
- 유한개의 halfspaces와 hyperplanes의 intersection
- $$A$$가 postive semi definite 또는 positive definite일때 convex set

Operations that Preserve Convexity
----------------------------------

- **Lemma:** Let $$I$$ be an arbitrary index set. If the sets $$S_i \subseteq \mathbf{R^n}, i\in I$$, are convex sets, then $$S=\bigcap_{i\in I}S_i$$ is convex
	- **Proof:** Let $$x\in S$$. Then $$x\in S_i$$ for all $$i \in I$$. Since $$S_i$$ is convex for all $$i\in I$$, the result follows immediately.
	- Union아닌 Intersection만 convexity preserve

- **Lemma:** The set $$\text{conv}(S)$$ is the set of all convex combinations of points in $$S$$. For any $$c \in \mathbf{R}$$, define

$$cS:=\{y\in \mathbf{R^n}:y=cx, x\in S \}$$

- and for any two sets $$S$$ and $$C$$

$$S+c:=\{z\in \mathbf{R^n}:z=x+y,x\in s \text{ and } y\in c\}$$

- Then the set $$Z=aS+bC$$ is convex
	- Namely, the scalar multiplication and addition preserve convexity

- **Lemma:** Let $$f:\mathbf{R^n} \to \mathbf{R^m}$$ with $$f=Ax+b$$. Then the image set defined by

$$f(S)=\{f(x)\vert x\in S\}$$

- where $$S$$ is a convex subset of $$\mathbf{R^n}$$ is a convex set. The inverse image set

$$f^{-1}(S)=\{x\vert f(x)\in S\}$$

- is also convex

**Perspective function**

- **Definition:** The perspective function $$P:\mathbf{R^n}\to \mathbf{R^{n-1}}$$ is defined by

$$P =\begin{pmatrix} x_1/x_n\\x_2/x_n \\ \vdots \\x_{n-1}/x_n \end{pmatrix}=\frac{x}{t}$$

- where $$x_n=t >0$$.
- 참고로, convex domain $$C$$에 대해서 $$P(C), P^{-1}(C)$$ 모두 convex
- **Proof:**

To show that $$P(C)$$ is convex, suppose that $$(x,x_n),(y,y_n)\in \mathbf{R^n}$$ with $$x_n,y_n>0$$. Then for any $$\theta \in [0,1]$$, we have

$$P(\theta x+(1-\theta)y)=\frac{\theta x+(1-\theta)y}{\theta x_n+(1-\theta)y_n}\\=\frac{\theta x_n}{\theta x_n+(1-\theta)y_n}\frac{x}{x_n}+\frac{(1-\theta)y_n}{\theta x_n+(1-\theta)y_n}\frac{y}{y_n}\\=\mu P(x)+(1-\mu)P(y)$$

Then since C is convex, P(C) is convex

**Linear fractional transformation**

- **Definition:** composition of the perspective function with an affine(linear) function

$$g(x) =\begin{pmatrix} A\\c^T \end{pmatrix}x+\begin{pmatrix} b\\d \end{pmatrix}$$

$$f(x) = P(g(x))=\frac{Ax+b}{c^Tx+d}$$

- If $$C$$ is convex, and is a subset of domain of $$f$$, then $$f(C)$$ is convex
- Example: conditional probability

Separating and Supporting Hyperplanes
-------------------------------------

**Separating hyperplane**

- **contrained optimizaion problem과 duality와도 상관있는 중요한 부분**
- 나중에 좀더 깊게 다룰것
- **Theorem:** Suppose that $$C$$ and $$D$$ are two convex sets such that $$C\land D = \emptyset$$. Then there exsits $$a \ne 0$$ and $$b$$ such that $$a^Tx \le b$$ for all $$x\in C$$ and $$a^Tx \ge b$$ for all $$x\in D$$. The hyperplane $$a^Tx=b$$ is called the separating hyperplane.

**Supporting hyperplane**

- **Theorem:** For a convex set $$C$$, if $$a\le 0$$ satisfies $$a^Tx \le a^Tx_0$$ for all $$x \in C$$, then the hyperplane $$\{x\vert a^Tx=a^Tx_0\}$$ is called a supporting hyperplane to $$C$$ at $$x_0$$. Namely, the hyperplane is tangent to $$C$$ at $$x_0$$
- **Theorem:** For any nonempty convex set $$C$$ and any $$x_0\in bd(C)$$, there exists a supporting hyperplane to $$C$$ at $$x_0$$
	- The proof of the supporting hyperplane theorem follows from the separating hyperplane theorem.
