---
layout: page-sidenav
group: "Introduction to Optimization"
title: "1. Convex Optimizaion"
---

Outline
-------

>지금까지 Existence, convex sets , convex functions배웠다.
>이번에는 convex optimization을 배워보자.
>책에서 4.1, 4.2부분만 다룸

Convex Optimization
-------------------

$\underset{x}{\text{min}}f(x)$

$\text{s.t. } f_i(x) \le 0, \forall i=1,2,...,m$

$a_i^Tx=b_i, \forall j = 1,2,...,p$

- Convex optimization 문제가 되기 위해서는..
	- The objective function must be convex
	- The inequality constraint function must be convex
	- The equality constraint must be affine
- 따라서 위와 같은 꼴로 만들어 주어야 한다.
- 예시들을 살펴 보자.

$\underset{x}{\text{min}}f(x)$

$\text{s.t. } Ax \ge b$

- 위와 같은 문제를 아래와 같이 전형적인 Convex optimization 문제 꼴로 바꿀 수 있다.

$\underset{x}{\text{min}}f(x)$

$\text{s.t. } Ax +s = b$

$s\ge 0$

- 이때 s를 slack variable이라 한다
- 한가지 예시를 더 살펴보자

$\underset{x}{\text{min}}f(A_0x+b_0)$

$\text{s.t. } g_j(A_jx+b_j) \le 0, j=1,2,...,m$

- 위와 같은 문제를 아래와 같이 전형적인 Convex optimization 문제 꼴로 바꿀 수 있다.

$\underset{x}{\text{min}}f(y_0)$

$\text{s.t. } g_j(y_j) \le 0, j=1,2,...,m$

$y_j=A_jx+b_j, j=0,1,...,m$

**Epigraph form optimization**

- 또한 Ch4에서 배운 Epigraph를 활용해 문제를 변형 할 수도 있다. (Epigraph가 convexity를 보존하기 때문에)
- 예를 들어,

$\underset{x}{\text{min}}f(x)$

$\text{s.t. } g(x) \le 0, Ax =b$

- 위의 문제를 아래와 같이,

$\text{min }w$

$\text{s.t. } f(x) \le w$

$g(x) \le 0, Ax =b$

- Epigraph를 이용해 x에 관해 최소화 하던 문제를 w에 대해 최소화 하는 문제로 바꿀 수 있다.

Useful Facts
------------

- 왜 Convex optimization이 중요할까?
- **Fact:** If $x^*$ is a local minimum, then it is algo global minimum point for a convex optimization problem.
- **Fact:** Let $S$ be the set of all global minimizers for the convex optimization problem. Then $S$ is a convex set
- **Fact:** The first order necessary optimality condition becomes sufiicient for the convex optimization problem.
- **Fact:** If $f$ is strictly convex, then there exist a unique minimizer.

Problem with Equality Constraint
--------------------------------

- consider

$\underset{x}{\text{min}}f(x)$

$\text{s.t. } Ax=b$

- if $f$ is convex, then $x^*$ is the minimizer iff

$\nabla f(x^*)^T(y-x^*) \ge 0 \; \forall y, Ay = b$

- Note that $Ax^*=b$. We then have

$\nabla f(x^*)^Tz \ge 0 \; \forall z, A(z+x^*) = b$

$\Leftrightarrow \nabla f(x^*)^Tz \ge 0 \; \forall z, Az = 0$

- Since $-Az=0$,

$\Leftrightarrow \nabla f(x^*)^Tz = 0 \; \forall z, Az = 0$

- Let $N(A)$ and $R(A)$ be the null and column spaces of $A$, respectively.
- By the fact that

$N(A) \perp R(A^T)$

$z \in N(A)$

$z \perp \nabla f(x^*)^T$

- we can know

$\nabla f(x^*)^T \in R(A^T)$

$\nabla f(x^*)^T = A^Tu$

- This means that there exists a vector $u$ such that $\nabla f(x^*)^T = A^Tu$.
- Therefore, $x^*$ is an optimal solution iff

$\exists u \; \nabla f(x^*)^T - A^Tu = 0, \; Ax^*=b$

내용 정리
--------

- Convex Optimization의 중요성을 배울 수 있었다
	- local point를 global로 만들어 주고
	- The first order necessary optimality condition을 충분조건으로 만들어 주며
	- Strictly convex할 경우 uniqueness를 보장해준다
- 전형 적인 Convex Optimization문제 형식으로 바꾸기 위한 방식을을 배울 수 있었다
- Convex Optimization 문제 중에서도 Equality Constraint 경우에는 단순히 Unconstraint한 연립 방정식 문제로 바꿀 있다!.

