---
layout: page-sidenav
group: "Introduction to Optimization"
title: "3. Convex Functions"
---


Outline
-------

- Definition of the convex function
- Examples
- Convex function operation

Convex Functions
----------------

**Convex function**

![]({{site.baseurl}}/images/opt_study/intro_opt/3.1.png){:class="center-block"}

- **Defintion:** A function $$f:\mathbf{R^n}\to \mathbf{R}$$ is convex if the domain $$f\text{,dom}(f)$$ is a convex set, and if for any $$\theta \in [0,1]$$,

$$f(\theta x+(1-\theta)y)\le\theta f(x)+(1-\theta)f(y), \forall x,y \in \text{dom}(f)$$

- A function is strictly convex if the inequality is replaced by the strict equality with $$\theta \in (0,1)$$
- A function is concave if -f is convex
- **Convex function is defined on the convex set**
- The definition can be extended to

$$f(\sum_{j=1}^{k}\alpha_jx_j) \le \sum_{j=1}^{k}\alpha_jf(x_j)$$

for all $$\alpha_j \ge 0$$ and $$\sum_{j=1}^{k}a_j=1$$

- **Theorem:** A function $$f$$ is convex if and only if $$f$$ is convex when it is restricted to any line that intersects its domain. That is, $$f$$ is convex if and only if for any $$x\in \text{dom}(f)$$, and $$v,g(t)=f(x+tv)$$ is convex
	- 이 Theorem을 이용하면 $$\mathbf{R^n}$$ domain 에서가 아니라 $$\mathbf{R}$$ domain 에서 convex analysis 가능.
- **Proof($$\Rightarrow$$):**

Suppose that $$f$$ is convex. Then we need to show that $$g$$ is convex. Consider,

$$g(\alpha t_1 +(1-\alpha)t_2)\\=f(x+(\alpha t_1+(1-\alpha)t_2)v)\\=f(\alpha x+(1-\alpha)x+(\alpha t_1+(1-\alpha)t_2)v)
\\=f(\alpha(x+t_1v)+(1-\alpha)(x+t_2v))\\ \le \alpha f(x+t_1v)+(1-\alpha)f(x+t_2v)\\=\alpha g(t_1)+(1-\alpha)g(t_2)$$

- **Proof($$\Leftarrow$$):**

Let $$v=(y-x)$$. Then

$$g(t) = f(x+t(y-x)),g(t-1)=f(x+(t-1)(y-x))$$

Since $$g$$ is convex for any $$t$$, for any $$\alpha \in [0,1]$$

$$g((1-\alpha)t+\alpha (t-1)) \le \alpha g(t-1)+(1-\alpha)g(t)$$

Let $$t=1$$. Then

$$g(1-\alpha) \le \alpha g(0)+(1-\alpha)g(1)
\\ \Leftrightarrow f(\alpha x+(1-\alpha)x+(1-\alpha)(y-x))\le \alpha f(x)+(1-\alpha)f(y)
\\ \Leftrightarrow f(\alpha x+(1-\alpha)y) \le \alpha f(x)+(1-\alpha)f(y)$$

First order condition for convexity
-----------------------------------

![]({{site.baseurl}}/images/opt_study/intro_opt/3.2.png){:class="center-block"}

- Suppose that $$f$$ is differentiable. Then $$f:S\to \mathbf{R}$$ is convex if and only if $$S$$ is convex and

$$f(y) \ge f(x) + \nabla f(x)^T(y-x), \forall x,y \in S$$

- Connection with the first order necessary condition. If $$x^*$$ is optimal, then

$$\nabla f(x^*) = 0, f(y) \ge f(x^*), \forall y \in S$$

- $$x^*$$ is a global minimum point.
	- ch1에서 배운 first order condition for optimal point를 생각해보자.
	- $$\nabla f(x^*) = 0$$은 optimal point를 가지기 위한 일차 필요조건이였다.
	- 하지만 convex가 보장이 되면 $$\nabla f(x^*) = 0$$은 $$0$$이 되어 $$f(y) \ge f(x^*)$$이되고
		- local optiaml문제에서 global optimal문제가 되고
		- ch1에서 배운 optimal point에 대한 일차 필요조건이 충분조건이 된다.
	- Convex의 중요성 :)
- **Proof($$\Rightarrow$$):**

We will prove the one-dimensional case.
Assume that $$f$$ is convex. Then we have

$$f(x+t(y-x)) \le (1-t)f(x)+tf(y)
\\ \Leftrightarrow f(y) \ge f(x)+\frac{f(x+t(y-x))-f(x)}{t}$$

and by taking the limit $$t \to 0$$, we have the desired result

- **Proof($$\Leftarrow$$):**

Suppose now that we have the first order condition. Let $$z=\theta x+(1-\theta)y$$. Then

$$f(x) \ge f(z)+\nabla f(z)(x-z)$$

$$f(y) \ge f(z)+\nabla f(z)(y-z)$$

Then

$$\theta f(x)+(1-\theta)f(y) \ge f(z) = f(\theta x+(1-\theta)y)$$

Second order condition for convexity
------------------------------------

- Twice differentiable function $$f:S\to R$$ is convex iff $$S$$ is convex and

$$\nabla^2f(x)=H \ge 0$$

- The Hessian must be positive semi-definite
- For the strict convexity, $$H > 0$$

Convex Functions: Examples
--------------------------

**Quadratic optimization probelm (like the least sqaure problem)**

$$f(x)=\frac{1}{2}x^TPx+q^Tx+r$$

- is convex iff $$P\ge 0$$, and is strictly convex iff $$P>0$$.
- The least square problem $$f(x) = \vert\vert Ax-b \vert\vert^2$$ is convex
- 증명은,intersection with an arbitrary line $$\{\hat x+tv \vert \; t \in \mathbf{R}\}$$ 을 이용해 보일 수 있다.
- 앞에서 배운 Convex를 보이기 위한 Theorem 참고.

**Convex function examples on $$\mathbf{R}$$:**

- affine: $$ax+b$$
	- 참고로 affine은 convex이면서 concave
- exponential: $$e^{ax}$$
- powers: $$x^{\alpha}$$ for $$\alpha > 1$$
- powers of absolute value: $$\vert x\vert^p$$ on $$\mathbf{R}$$ where $$p \ge 1$$
	- triangularity로 보일 수 있다.
- negative entropy: $$xlogx$$ on $$\mathbf{R}$$: 2nd order derivative is positive
- 참고로 $$logx$$는 concave

**Convex function examples on $$\mathbf{R^n}$$ and $$\mathbf{R^{m\times n}}$$:**

- norm: $$\vert\vert \cdot \vert\vert$$
- $$f(x)=\max\{ x_1,...,x_n \}$$
- affine function
	- affine이 convex한 것과 $$\text{Tr}(A+B) = \text{Tr}(A) + \text{Tr}(B)$$를 이용해 증명 가능

$$f(x)=\text{Tr}(A^TX)+b $$

- induced norm (singular value) : norm of the matrix

$$\vert\vert X\vert\vert_2 = \underset{\vert\vert v\vert\vert \ne 0}{\text{sup}} \frac{\vert\vert Xv\vert\vert_2}{\vert\vert v\vert\vert_2}= (\lambda_max(X^TX))^{1/2}$$

**log-determinant function**

- Example: $$f: \mathbf{S^n}\to \mathbf{R}$$ with $$f(X)=\log\det(x)$$
- log-determinant가 concave한 것을 intersection with an arbitrary line을 이용해 증명해 보자.

$$g(t) = log\det(X+tV)
\\=\log\det(X^{1/2}(I+tX^{-1/2}VX^{-1/2})X^{1/2})
\\=\log\det X + \log\det (I+tX^{-1/2}VX^{-1/2})
\\=\log\det X + \sum_{i=1}^n \log(1+t\lambda_i)$$

- where $$\lambda_i$$ are eigenvalues of $$X^{-1/2}VX^{-1/2}$$.
- $$g(t)$$는 $$t$$에 대해서 $$\log$$때문에 concave함
- 실제로 $$g''=-\sum_{i=1}^n \frac{\lambda_i^2}{(1+t\lambda_i)^2} < 0$$, strictly concave

**Example: $$f(x,y)=x^2/y$$ where $$y > 0$$**

- eigen value를 이용해 convex를 증명해 보자.
- $$f_{xx} = 2/y$$
- $$f_{xy} = -2x/y^2$$
- $$f_{yy} = 2x^2/y^3$$
- $$\det H = 0$$, 즉 모든 eigen value의 곱은 0
	- $$\lambda_1 \lambda_2  = 0$$
- $$\text{Tr}(H) = \frac{2}{y} + \frac{2x^2}{y^3} > 0$$ where $$y>0$$, 즉 모든 eigen value의 합은 0보다 크다.
	- $$\lambda_1 + \lambda_2  > 0$$
- 따라서 모든 eigen value들이 0과 같거나 크므로, $$H$$ 는 positive semi-definite이고
- $$f$$는 convex하다

Epigraph and Sublevel Sets
--------------------------

![]({{site.baseurl}}/images/opt_study/intro_opt/3.3.png){:class="center-block"}

**$$\alpha$$-sublevel set**
- **Definition:** $$\alpha$$-sublevel set of $$f:\mathbf{R^n} \to \mathbf{R}$$

$$C_{\alpha} = \{x \in \text{dom}(f) \vert \; f(x) \le \alpha \}$$

- sublevel set of convex functions are convex.
- **But the converse is not true**
- 즉, $$C_{\alpha}$$는 $$f$$가 $$\alpha$$보다 작은 범위 내의 domain

**Epigraph**
- **Definition:** epigraph of $$f:\mathbf{R^n} \to \mathbf{R}$$:

$$\text{epi}(f)=\{ (x,t) \in \mathbf{R^n} \vert \; x \in \text{dom}(f),\; f(x) \le t \}$$

- A function $$f$$ is convex iff $$\text{epi}(f)$$ is convex.
- **Convex를 보이는 한 방법!** (differentiable 할 필요 x)
- **Ch5에서 duality를 다룰 때 또 사용 될 것**

Jensen's Inequality
-------------------

**Jensen's Inequality**

- Convex combination version: If $$f$$ is convex, then with $$\theta_i \ge 0$$ and $$\sum_{i=1}^k\theta_i=1$$,

$$f(\theta_1x_1+\dots+ \theta_kx_k ) \le \sum_{i=1}^k \theta_i f(x_i)$$

- Random vector: if $$f$$ is convex, then

$$f(E[x]) \le E[f(x)]$$

**Holder's Inequality**

$$\sum_i x_iy_i \le (\sum_i \vert x_i\vert^p)^{1/p}(\sum_i \vert y_i\vert^q)^{1/q}$$

- where $$\frac{1}{p}+\frac{1}{q}=1, \; p > 1$$

Operations that Preserve Convexity
----------------------------------

- Scaling: if $$f(x)$$ is convex, then $$\alpha f(x)$$ is convex
- Addition: if $$f_1$$ and $$f_2$$ are convex, then $$f_1 + f_2$$ is convex
- Composition with an affine function: $$f$$ is convex and $$g$$ is affine, then 
  $$f(g(x))$$ is convex

**Pointwise maximum**

- if $$f_1,f_2,...,f_m$$ are convex functions, then their pointwise maximum, defined by

$$f(x) = \max\{ f_1(x),f_2(x),...,f_m(x) \}$$

- pointwise maximum is also convex

**Pointwise supremum**

- If for each $$y \in S$$, $$f(x,y)$$ is convex, then the point wise supremum

$$g(x) = \underset{y\in S}{\text{sup}}f(x,y)$$

- is convex
- 참고로 $$S$$가 convex일 필요는 없다
- 또한

$$\text{epi}(g) = \cap_{y\in S}\text{epi}(f(\cdot,y))$$

- $$f$$가 convex하면 $$\text{epi}(f(\cdot,y))$$도 모든 y에 대해 convex하므로
  $$\text{epi}(g)$$는 convex하다. (왜냐하면, convex끼리의 교집합은 convex하므로) 

- 참고로
	- $$f(x,y)$$ is convex in (x,y), and $$C$$ is convex and nonempty, then
	- $$g(x) = \underset{y\in C}{\text{inf}}f(x,y)$$ 또한 convex하다
	- 이때는 Pointwise supremum과 다르게 $$C$$는 반드시 convex해야한다


**Scalar composition**

- Suppose $$f(x)=h(g(x))$$ where $$h:\mathbf{R} \to \mathbf{R}$$ and $$g:\mathbf{R^n} \to \mathbf{R}$$
	- $$f$$ is convex if $$h$$ is convex and nondecreasing and $$g$$ is convex
		- e.g., $$\exp g(x)$$ if $$g$$ is convex
	- $$f$$ is convex if $$h$$ is convex and nonincreasing and $$g$$ is concave
		- e.g., $$1/g(X)$$ if $$g$$ is concave and positive
	- $$f$$ is concave if $$h$$ is concave and nondecreasing and $$g$$ is concave
	- $$f$$ is concave if $$h$$ is concave and nonincreasing and $$g$$ is convex

**Vector composition**

- Suppose $$f(x)=h(g(x))$$ where $$h:\mathbf{R^k} \to \mathbf{R}$$ and $$g:\mathbf{R^n} \to \mathbf{R^k}$$
	- $$f$$ is convex if $$h$$ is convex and nondecreasing in each argument and $$g_i$$ is convex
	- $$f$$ is convex if $$h$$ is convex and nonincreasing in each argument and $$g_i$$ is concave
- Scalar composition과 같은 맥락 단 $$h$$의 input이 vector

**Perspective Function**

- If $$f:\mathbf{R^n} \to \mathbf{R}$$, the perspective of $$f$$ is the function $$g:\mathbf{R^{n+1}} \to \mathbf{R}$$ defined by

$$g(x,t)=tf(\frac{x}{t})$$

- $$f$$가 convex하면 perspective operation은 convexity 보존
- 증명은 Epigraph를 통해 가능


내용 정리
-------
- 지금 까지 배운 Convex를 보이는 5가지 방법
	1. By definition
	2. By the intersection with an arbitrary line $$g(t) = x+tv$$
	3. $$f(y) \ge f(x) + \nabla f(x)^T(y-x), \forall x,y \in S$$
	4. $$H \ge 0$$
	5. Epigraph (differentiable 할 필요 x)