---
layout: page-sidenav
group: "Web crawling"
title: "2. 웹 크롤링 bs4 & requests"
---

> Python을 이용해 웹 크롤링을 어떻게 할 수 있을지 간단히 살표보자
> 쉬운 방법으로는 Python의 requests, bs4 라이브러리를 사용하는 것이다.

Beautifule Soup(bs4)
-------------------

- html문서에서 원하는 정보를 손쉽게 가져올 수 있는 방법을 제공.
- 일종의 Parsor 역할을 수행
- 자동으로 인코딩을 유니코드로 변환해서 UTF-8로 출력  
- HTML문서를 가져오기 위해 requests 이용

실전 예시
--------

![]({{site.baseurl}}/images/web_study/web_crawling/1.png){:class="center-block"}

가령 위와 같은 [사이트](http://http://stock.navle.net/)에서 종목 code 520009의 시가 총액값을 가져오고 싶다고 해보자.
(참고로 해당 회사는, **대우 레버리지 원유선물혼합**	이다)


실제로 해당 사이트에서 520009를 검색해 보자.
검색을 해보면 아래와 같은 페이지를 확인할 수 있을것이다. 

![]({{site.baseurl}}/images/web_study/web_crawling/2.png){:class="center-block"}

해당 회사의 시가총액은 228임을 확인 할 수 있다. (**참고로, 검색 전과 url이 달라진 것도 확인 할 수 있다. 이는 뒤에서 다룰 것이다**)그렇다면 어떻게 우리가 원하는 시가총액만 따로 가져올 수 있을까?

구글 크롬으로 해당페이지를 열고 컨트롤+시프트+i 키를 동시에 눌러 Developer tool을 열어보자. 아래와 같이 해당 페이지의 html이 어떻게 구성되어 있는지 확인 할 수 있다. 컨트롤 + F 키를 동시에 눌러 228을 검색해보자.

![]({{site.baseurl}}/images/web_study/web_crawling/3.png){:class="center-block"}

`<td class="m_no">`안에 우리가 원하는 값이 들어 있는걸 확인 할 수 있다. HTML을 유심히 살펴 보면 그 위에 `<td class='cast'>` 안에 ETN 값이 담겨잆는걸 확인 할 수 있다. 좀더 HTML을 유심히 살펴보면 `<td class='cast'>`안에는 해당 사이트의 분류의 해당하는 값이 적혀있다. 따라서 전략은 간단하다. `<td class='cast'>`들중에 마지막 것 (마지막 열)을 찾고 그 다음에 해당하는 `<td class="m_no">`중에 228 값이 들어있는 것 을 찾으면 된다.

해당 코드는 아래와 같다.

```{.python}
import requests
from bs4 import BeautifulSoup

code = '520009'

url = 'http://stock.navle.net'
html = requests.post(url,data={"_filter":'search','search_keyword':code,'search_target':'title_content'})
soup = BeautifulSoup(html.content)
stock_type = soup.findAll('td',{"class":"cate"})[-1]
total_val = stock_type.findNextSiblings('td',{"class":"m_no"})[6]
print(total_val.text[2:])
```

위의 코드는 크게 두 부분으로 나뉜다.
1. requests를 통해 해당 페이지의 html을 가져온다. 이때 url 뿐만아니라 다른 인자들도 넣어주어야 하는데 가령 검색어(keyword)에는 052009를 넘겨주는 것이다. **이전에 검색을 했을때 url 뒷부분이 바뀐 이유를 생각해보면 쉽게 이해할 수 있을것이다.**
2. BeautifulSoup을 이용해 웹에서 가져온 HTML은 분석해서 원하는 정보만 가져온다.

